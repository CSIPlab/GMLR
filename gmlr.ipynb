{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in sequence: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakib/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:88: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/rakib/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:89: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/rakib/anaconda2/lib/python2.7/site-packages/torch/serialization.py:391: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 20.409563635448595\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from scipy import misc, linalg\n",
    "import torch\n",
    "from os.path import isfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skvideo.io\n",
    "\n",
    "# Sequence Directory\n",
    "sequence_dir='data/archery/'\n",
    "sequence_files=sorted(glob(sequence_dir+'*.jpg'))\n",
    "sequence_size=len(sequence_files)\n",
    "print('Number of frames in sequence: '+str(sequence_size))\n",
    "\n",
    "\n",
    "z_dim=256  # Dimension of latent code\n",
    "z_init='fixed_seed' # fixed_z, fixed_seed, random_seed\n",
    "seed=100 # Used when fixed seed or fixed_z is selected\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc  = 3\n",
    "\n",
    "measurement_type='missing' #'original', 'linear','missing'\n",
    "num_measurements=512 # Used only for linear measurements\n",
    "missing_ratio=0.8  # Used only for missing pixels\n",
    "if measurement_type=='original':\n",
    "    num_measurements=ngf*ndf*nc\n",
    "elif measurement_type=='missing':      \n",
    "    num_measurements=np.int(ngf*ndf*nc*(1-missing_ratio))\n",
    "matrix_id=1\n",
    "\n",
    "low_rank=2 # Can be at most max([z_dim,sequence_size]), If it is 0, then low rank constraint is not applied\n",
    "low_rank_type='pca' #'svd': Select top r singular value; 'pca': Select mean and top r-1 pca components\n",
    "lamda= 1 # Weight on similarity constraint, total loss= lamda* MSE+ (1-lamda)* similarity constraint\n",
    "\n",
    "update_type='joint'#'latent','gen','joint'\n",
    "test_size=sequence_size\n",
    "test_epochs=500\n",
    "test_batch_size=sequence_size\n",
    "\n",
    "opt='sgd' #'sgd','adam'\n",
    "if opt=='sgd':\n",
    "    lr=1*test_batch_size/256\n",
    "    alpha=200*test_batch_size/256\n",
    "elif opt=='adam':\n",
    "    lr=0.0001*test_batch_size/256\n",
    "    alpha=200*test_batch_size/256\n",
    "    \n",
    "video_gen=1 # It will save the video sequence\n",
    "video_name='video/archery'\n",
    "\n",
    "# Initial weights of the generator\n",
    "model_init='Model/CIFAR10_resize64_dcgan'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = torch.nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            torch.nn.ConvTranspose2d(    z_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            torch.nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2,1, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            torch.nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            torch.nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "#            # state size. (ngf) x 32 x 32\n",
    "            torch.nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            torch.nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = torch.nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output    \n",
    "generator = Generator(1).to(device)\n",
    "\n",
    "x_test=[]\n",
    "for i in range (0,sequence_size):\n",
    "    img=misc.imread(sequence_files[i])\n",
    "    img=misc.imresize(img,[ngf,ndf])\n",
    "    img=img/255.0\n",
    "    temp=np.zeros((img.shape[2],img.shape[0],img.shape[1]))\n",
    "\n",
    "    for chan in range (0,temp.shape[0]):\n",
    "        temp[chan,:,:]=img[:,:,chan]\n",
    "    x_test.append(temp)\n",
    "x_test=np.array(x_test)\n",
    "\n",
    "z_test=np.zeros((x_test.shape[0],z_dim))\n",
    "if z_init=='fixed_seed':\n",
    "    np.random.seed(seed)\n",
    "for i in range (0,z_test.shape[0]): \n",
    "    if z_init=='fixed_z':\n",
    "        np.random.seed(seed)\n",
    "    z_test[i,:]=np.random.normal(loc=0, scale=1.0, size=(1,z_dim))\n",
    "\n",
    "    \n",
    "if isfile('/measurement_matrix/batch_'+str(test_batch_size)+'_'+str(measurement_type)+'_'+str(num_measurements)+'_'+str(matrix_id)+'.npy'):\n",
    "    A=np.load('/measurement_matrix/batch_'+str(test_batch_size)+'_'+str(measurement_type)+'_'+str(num_measurements)+'_'+str(matrix_id)+'.npy')\n",
    "\n",
    "elif measurement_type=='linear':\n",
    "    A =np.random.normal(loc=0.0, scale=1.0/np.sqrt(num_measurements), size=(test_batch_size,num_measurements,nc*ngf*ndf))\n",
    "    np.save('measurement_matrix/batch_'+str(test_batch_size)+'_'+str(measurement_type)+'_'+str(num_measurements)+'_'+str(matrix_id),A)\n",
    "             \n",
    "elif measurement_type=='missing':    \n",
    "    A=np.ones((test_batch_size,nc,ngf,ndf))\n",
    "    idx=np.arange(ngf*ndf)\n",
    "    for i in range (0,test_batch_size):\n",
    "        A_temp =np.ones((1,ngf*ndf))\n",
    "        np.random.shuffle(idx)                \n",
    "        A_temp[0,idx[0:np.int(ngf*ndf*missing_ratio)]]=0\n",
    "\n",
    "        A_temp=np.reshape(A_temp,(ngf, ndf))\n",
    "        A_c=np.zeros((ngf,ndf,nc))\n",
    "        for j in range (0,nc):\n",
    "            A_c[:,:,j]=A_temp            \n",
    "        for j in range (0,nc):\n",
    "            A[i,j,:,:]=A_c[:,:,j]\n",
    "    np.save('measurement_matrix/batch_'+str(test_batch_size)+'_'+str(measurement_type)+'_'+str(num_measurements)+'_'+str(matrix_id),A)\n",
    "\n",
    "\n",
    "x_test_org=x_test\n",
    "if measurement_type=='linear':\n",
    "    x_test=2*x_test-1\n",
    "    x_test_temp=np.zeros((x_test.shape[0],num_measurements,1))\n",
    "    for i in range (0, x_test.shape[0]):\n",
    "        x_test_temp[i,:,:]=np.matmul(A[i%test_batch_size,:,:],x_test[i,:,:,:].reshape(1,nc*ngf*ndf,1))\n",
    "    x_test=x_test_temp\n",
    "elif measurement_type=='original': \n",
    "    x_test=2*x_test-1\n",
    "    x_test=x_test  \n",
    "elif measurement_type=='missing':\n",
    "    x_test_temp=np.zeros((x_test.shape[0],nc,ngf,ndf))\n",
    "    for i in range (0, x_test.shape[0]):\n",
    "        x_test_temp[i,:,:]=np.multiply(x_test[i,:,:,:],A[i%test_batch_size,:,:,:])\n",
    "    x_test=x_test_temp\n",
    "    x_test=2*x_test-1\n",
    "\n",
    "batch_no=np.int(np.ceil(test_size/np.float(test_batch_size)))\n",
    "idx=np.arange(test_size)\n",
    "loss_test=[]\n",
    "loss_z_test=[]\n",
    "x_rec=np.zeros((x_test.shape[0],nc,ngf,ndf))\n",
    "for batch_idx in range(0,batch_no):\n",
    "    # Initialize generator\n",
    "    generator = torch.load(model_init)\n",
    "    if opt=='sgd':\n",
    "        optimizer = torch.optim.SGD(generator.parameters(), lr)\n",
    "    elif opt=='adam':\n",
    "        optimizer = torch.optim.Adam(generator.parameters(), lr)\n",
    "    loss_epoch=[]\n",
    "    loss_z_epoch=[]\n",
    "    epoch_idx=idx\n",
    "    \n",
    "    if measurement_type=='original':\n",
    "        x_batch=x_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:,:,:]\n",
    "        x_batch_tensor=torch.cuda.FloatTensor(x_batch).view(-1,nc,ngf,ndf)\n",
    "    elif measurement_type=='missing':\n",
    "        x_batch=x_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:,:,:]\n",
    "        x_batch_tensor=torch.cuda.FloatTensor(x_batch).view(-1,nc,ngf,ndf)\n",
    "        A_tensor=torch.cuda.FloatTensor(A[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])]%test_batch_size,:,:]).view(-1,nc,ngf,ndf)\n",
    "    elif measurement_type=='linear':\n",
    "        x_batch=x_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:,0]\n",
    "        x_batch_tensor=torch.cuda.FloatTensor(x_batch).view(-1, x_batch.shape[1],1)\n",
    "        A_tensor=torch.cuda.FloatTensor(A[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])]%test_batch_size,:,:]).view(-1,num_measurements,nc*ngf*ndf)\n",
    "\n",
    "    for epoch in range (0,test_epochs):\n",
    "\n",
    "        z_batch=z_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:]\n",
    "        z_batch_tensor=torch.autograd.Variable(torch.cuda.FloatTensor(z_batch).view(-1, z_dim, 1, 1),requires_grad=True)\n",
    "\n",
    "        x_hat = generator(z_batch_tensor)\n",
    "        if measurement_type=='linear':\n",
    "            x_measure=torch.matmul(A_tensor,x_hat.view(-1, nc* ngf*ndf,1))\n",
    "        elif measurement_type=='original':\n",
    "            x_measure=x_hat\n",
    "        elif measurement_type=='missing':\n",
    "            x_hat_2=x_hat/2+0.5\n",
    "            x_measure_1=torch.mul(x_hat_2,A_tensor)\n",
    "            x_measure=2*x_measure_1-1\n",
    "\n",
    "        loss_mse=(x_measure - x_batch_tensor).pow(2).mean()\n",
    "\n",
    "        if test_batch_size>2:\n",
    "            for i in range (0, np.int(np.ceil(z_batch.shape[0]/np.float(sequence_size)))):\n",
    "                z_for=z_batch_tensor[i*sequence_size+1:np.min([(i+1)*sequence_size,test_batch_size]),:]\n",
    "                z_back=z_batch_tensor[i*sequence_size:np.min([(i+1)*sequence_size,test_batch_size])-1,:]\n",
    "                if i==0:\n",
    "                    loss_z=(z_for-z_back).pow(2).mean()\n",
    "                else:\n",
    "                    loss_z=loss_z+(z_for-z_back).pow(2).mean()\n",
    "            loss_z=loss_z\n",
    "\n",
    "            loss=lamda*loss_mse+(1-lamda)*loss_z\n",
    "        else:\n",
    "            loss=lamda*loss_mse\n",
    "\n",
    "        loss_epoch.append(loss.item())\n",
    "        \n",
    "        # Latent code optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)   \n",
    "\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            if update_type=='latent' or update_type=='joint':\n",
    "                z_grad = z_batch_tensor.grad.data.cuda()\n",
    "                z_update = z_batch_tensor - alpha * z_grad\n",
    "                z_update = z_update.cpu().detach().numpy()\n",
    "                z_update=np.reshape(z_update,z_batch.shape)\n",
    "                if low_rank!=0:\n",
    "                    if low_rank_type=='svd':\n",
    "                        u, s, vh = np.linalg.svd(z_update, full_matrices=False)\n",
    "                        z_update=np.dot(u * np.append(s[0:low_rank],np.zeros(len(s)-low_rank)), vh)\n",
    "                    elif low_rank_type=='pca':\n",
    "                        z_mean=np.mean(z_update,axis=0)\n",
    "                        z_temp=z_update-z_mean\n",
    "                        u, s, vh = np.linalg.svd(z_temp, full_matrices=False)\n",
    "                        z_new=np.dot(u * np.append(s[0:low_rank-1],np.zeros(len(s)-low_rank+1)), vh)\n",
    "                        z_update=z_new+z_mean\n",
    "                z_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:]=z_update\n",
    "        \n",
    "        # Generator parameter optimization        \n",
    "        if update_type=='gen' or update_type=='joint':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()   \n",
    "            optimizer.step()\n",
    "            \n",
    "        z_update_tensor=torch.autograd.Variable(torch.cuda.FloatTensor(z_test[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:]).view(-1, z_dim, 1, 1))    \n",
    "        x_hat = generator(z_update_tensor)\n",
    "        x_rec[epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])],:]=np.reshape(x_hat.cpu().detach().numpy(),(x_batch.shape[0],nc,ngf,ndf))\n",
    "\n",
    "    loss_test .append(np.array(loss_epoch))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(np.mean(np.array(loss_test),axis=0))  \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Reconstruction loss during testing')\n",
    "plt.title('Reconstruction loss vs epochs during testing')    \n",
    "plt.show()\n",
    "\n",
    "x_rec=x_rec/2+0.5\n",
    "mse=np.mean((x_rec-x_test_org)**2)\n",
    "psnr=20*np.log10((np.max(x_test_org)-np.min(x_test_org))/np.sqrt(mse))\n",
    "print('PSNR: ' +str(psnr))\n",
    "\n",
    "# Figures\n",
    "corrupt=0\n",
    "if measurement_type=='missing':\n",
    "    corrupt=1\n",
    "start_fig=0\n",
    "n=20    \n",
    "plt.figure(figsize=(n, 2+corrupt))\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    if nc==1:\n",
    "        # Plot reconstruction\n",
    "        ax = plt.subplot(2+corrupt, n, i + 1)\n",
    "        plt.imshow(x_rec[i+start_fig].reshape(ngf, ndf))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # Plot original\n",
    "        ax = plt.subplot(2+corrupt, n, i + 1+1*n)\n",
    "        plt.imshow(x_test_org[i+start_fig].reshape(ngf, ndf))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if corrupt==1:\n",
    "            # Plot inpainted\n",
    "            ax = plt.subplot(2+corrupt, n, i + 1+2*n)\n",
    "            plt.imshow((x_test[i+start_fig]/2+0.5).reshape(ngf, ndf))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    elif nc==3:\n",
    "        # Plot reconstruction\n",
    "        ax = plt.subplot(2+corrupt, n, i + 1)\n",
    "        temp=x_rec[i+start_fig]\n",
    "        temp1=np.zeros((ngf, ndf,nc))\n",
    "        for chan in range (0,nc):\n",
    "            temp1[:,:,chan]=temp[chan,:,:]\n",
    "        plt.imshow(temp1)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # Plot original\n",
    "        ax = plt.subplot(2+corrupt, n, i + 1+1*n)\n",
    "        temp=x_test_org[i+start_fig]\n",
    "        temp1=np.zeros((ngf, ndf,nc))\n",
    "        for chan in range (0,nc):\n",
    "            temp1[:,:,chan]=temp[chan,:,:]\n",
    "        plt.imshow(temp1)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if corrupt==1:\n",
    "            # Plot inpainted sequence\n",
    "            ax = plt.subplot(2+corrupt, n, i + 1+2*n)\n",
    "            temp=x_test[i+start_fig]/2+0.5\n",
    "            temp1=np.zeros((ngf, ndf,nc))\n",
    "            for chan in range (0,nc):\n",
    "                temp1[:,:,chan]=temp[chan,:,:]\n",
    "            plt.imshow(temp1)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "# Save video sequences            \n",
    "if video_gen==1:\n",
    "    outputdata = x_test_org * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    x_test_vid=np.zeros((outputdata.shape[0],ngf, ndf,nc))\n",
    "    for i in range(0,outputdata.shape[0]):\n",
    "        temp=outputdata[i]\n",
    "        temp1=np.zeros((ngf, ndf,nc))\n",
    "        for chan in range (0,nc):\n",
    "            temp1[:,:,chan]=temp[chan,:,:]\n",
    "        x_test_vid[i]=temp1\n",
    "    writer = skvideo.io.FFmpegWriter(video_name+'_true_resize'+str(ngf)+'.mp4')\n",
    "    for i in xrange(x_test_vid.shape[0]):\n",
    "            writer.writeFrame(x_test_vid[i, :, :, :])\n",
    "    writer.close()\n",
    "\n",
    "    outputdata = x_rec * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    x_test_vid=np.zeros((outputdata.shape[0],ngf, ndf,nc))\n",
    "    for i in range(0,outputdata.shape[0]):\n",
    "        temp=outputdata[i]\n",
    "        temp1=np.zeros((ngf, ndf,nc))\n",
    "        for chan in range (0,nc):\n",
    "            temp1[:,:,chan]=temp[chan,:,:]\n",
    "        x_test_vid[i]=temp1\n",
    "    writer = skvideo.io.FFmpegWriter(video_name+'_rec_resize'+str(ngf)+measurement_type+str(num_measurements)+'.mp4')\n",
    "    for i in xrange(x_test_vid.shape[0]):\n",
    "            writer.writeFrame(x_test_vid[i, :, :, :])\n",
    "    writer.close()\n",
    "\n",
    "    if corrupt==1:\n",
    "        outputdata = (x_test/2+0.5) * 255\n",
    "        outputdata = outputdata.astype(np.uint8)\n",
    "        x_test_vid=np.zeros((outputdata.shape[0],ngf, ndf,nc))\n",
    "        for i in range(0,outputdata.shape[0]):\n",
    "            temp=outputdata[i]\n",
    "            temp1=np.zeros((ngf, ndf,nc))\n",
    "            for chan in range (0,nc):\n",
    "                temp1[:,:,chan]=temp[chan,:,:]\n",
    "            x_test_vid[i]=temp1\n",
    "        writer = skvideo.io.FFmpegWriter(video_name+'_inpainted_resize'+str(ngf)+measurement_type+str(num_measurements)+'.mp4')\n",
    "        for i in xrange(x_test_vid.shape[0]):\n",
    "                writer.writeFrame(x_test_vid[i, :, :, :])\n",
    "        writer.close()\n",
    "\n",
    "        \n",
    "\n",
    "if low_rank==2:        \n",
    "    zt=z_test\n",
    "    u, s, vh = np.linalg.svd(zt, full_matrices=False)\n",
    "    zt=np.dot(u * np.append(s[0:low_rank],np.zeros(len(s)-low_rank)), vh)\n",
    "\n",
    "    zb=linalg.orth(zt.T)\n",
    "    zb=zb.T\n",
    "    a1=np.matmul(zt[0:sequence_size,:],np.linalg.pinv(zb))\n",
    "    area=50\n",
    "    plt.figure()\n",
    "    start_seq=0\n",
    "    end_seq=sequence_size  \n",
    "    ax=plt.subplot()\n",
    "    plt.scatter(a1[start_seq:end_seq,0], a1[start_seq:end_seq,1],s=area,alpha=1)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Weight on orthogonal basis 1')\n",
    "    plt.ylabel('Weight on orthogonal basis 2')\n",
    "    plt.title('2D Representation of Latent Codes')\n",
    "    for i in range(a1.shape[0]):\n",
    "        ax.annotate('  '+str(i+1), (a1[i,0], a1[i,1]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8384, 3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_idx[batch_idx*test_batch_size:np.min([(batch_idx+1)*test_batch_size,test_size])]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
